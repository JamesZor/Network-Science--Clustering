{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0fe770bc-64ca-40cd-8919-1fb056709328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy import stats, optimize, linalg\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.linalg import svd\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn import metrics, preprocessing, cluster, decomposition\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "import community as community_louvain\n",
    "\n",
    "\n",
    "def get_numeric_labels(G, communities):\n",
    "    node_community = {}\n",
    "    for i, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            node_community[node] = i\n",
    "    return [node_community[node] for node in G.nodes()]\n",
    "\n",
    "\n",
    "### Methods \n",
    "def louvain(G,k):\n",
    "    return community_louvain.best_partition(G)\n",
    "\n",
    "def girvan_newman(G, k):\n",
    "    # Run the Girvan-Newman algorithm\n",
    "    comp = nx.community.girvan_newman(G)\n",
    "    # Get the k-th level of the dendrogram\n",
    "    communities = list(itertools.islice(comp, k))[-1]\n",
    "    # Create a dictionary to store the clustering\n",
    "    clustering = {}\n",
    "    # Assign cluster labels to nodes\n",
    "    for cluster_id, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            clustering[node] = cluster_id\n",
    "    \n",
    "    return clustering\n",
    "\n",
    "def label_propagation(G, k):\n",
    "    # Note: k is not used in this method, but we keep it for consistency with other methods\n",
    "    communities = nx.algorithms.community.label_propagation_communities(G)\n",
    "    clustering = {}\n",
    "    for i, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            clustering[node] = i\n",
    "    return clustering\n",
    "\n",
    "# k means \n",
    "def create_node_embeddings(G, dimensions=64, walk_length=30, num_walks=200):\n",
    "    node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=4)\n",
    "    model = node2vec.fit(window=10, min_count=1)\n",
    "    \n",
    "    # Create node embeddings\n",
    "    node_embeddings = {}\n",
    "    for node in G.nodes():\n",
    "        node_embeddings[node] = model.wv[node]\n",
    "    \n",
    "    return node_embeddings\n",
    "\n",
    "def kmeans_clustering(G, k):\n",
    "    # Create node embeddings\n",
    "    node_embeddings = create_node_embeddings(G)\n",
    "    \n",
    "    # Prepare the feature matrix\n",
    "    X = np.array(list(node_embeddings.values()))\n",
    "    \n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Create the clustering dictionary\n",
    "    clustering = {node: label for node, label in zip(node_embeddings.keys(), labels)}\n",
    "    \n",
    "    return clustering\n",
    "\n",
    "def kmedoids_clustering(G, k):\n",
    "    # Create node embeddings\n",
    "    node_embeddings = create_node_embeddings(G)\n",
    "    \n",
    "    # Prepare the feature matrix\n",
    "    X = np.array(list(node_embeddings.values()))\n",
    "    \n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform K-medoids clustering\n",
    "    kmedoids = KMedoids(n_clusters=k, random_state=42)\n",
    "    labels = kmedoids.fit_predict(X_scaled)\n",
    "    \n",
    "    # Create the clustering dictionary\n",
    "    clustering = {node: label for node, label in zip(node_embeddings.keys(), labels)}\n",
    "    \n",
    "    return clustering\n",
    "\n",
    "## Hope \n",
    "def BGC(W, args):\n",
    "    c = np.array(np.sqrt(W.sum(axis=0))).flatten()\n",
    "    c[c==0] = 1\n",
    "    c = 1.0/c\n",
    "    cinv = diags(c)\n",
    "\n",
    "    F = normalize(W, norm='l1', axis=1)\n",
    "    B = W.T\n",
    "    \n",
    "    Bc = cinv.dot(B)\n",
    "    \n",
    "    m, n = W.shape\n",
    "    dim = min(int(args.dim * args.k), min(m, n) - 1)\n",
    "\n",
    "    # print(f\"dimension={dim}\")\n",
    "\n",
    "    r = np.array(np.sqrt(W.sum(axis=1))).flatten()\n",
    "    r[r==0] = 1\n",
    "    r = 1.0/r\n",
    "    r = diags(r)\n",
    "    L = Bc.dot(r)\n",
    "    U, s, V = svds(L, k=dim)\n",
    "    s = s**2\n",
    "\n",
    "    alpha = args.alpha\n",
    "    s = (1.0-alpha)/(1.0-alpha*(s))\n",
    "    s = np.array(s).flatten()\n",
    "    s = diags(s).todense()\n",
    "    U = np.asarray(U.dot(s))  # Convert to numpy array\n",
    "    U = np.asarray(F.dot(U))  # Convert to numpy array\n",
    "    U = normalize(U, norm='l2', axis=1)\n",
    "\n",
    "    # print(\"start performing k-means...\")\n",
    "    clustering = KMeans(n_clusters=args.k, random_state=1024).fit(U)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    return labels\n",
    "\n",
    "def FNEM(W, args):\n",
    "    c = np.array(np.sqrt(W.sum(axis=0))).flatten()\n",
    "    c[c==0] = 1\n",
    "    c = 1.0/c\n",
    "    c = diags(c)\n",
    "\n",
    "    P = normalize(W, norm='l1', axis=1)\n",
    "    R = c.dot(W.T)\n",
    "    r = np.array(np.sqrt(W.sum(axis=1))).flatten()\n",
    "    r[r==0] = 1\n",
    "    r = 1.0/r\n",
    "    r = diags(r)\n",
    "    R = R.dot(r)\n",
    "\n",
    "    m, n = W.shape\n",
    "    dim = min(int(args.dim * args.k), min(m, n) - 1)\n",
    "\n",
    "    # print(f\"dimension={dim}\")\n",
    "\n",
    "    U, s, V = svds(R, k=dim)\n",
    "    s = s**2\n",
    "\n",
    "    alpha = args.alpha\n",
    "    s = (1.0-alpha)/(1.0-alpha*(s))\n",
    "    s = np.array(s).flatten()\n",
    "    s = diags(s).todense()\n",
    "    U = np.asarray(U.dot(s))\n",
    "    U = np.asarray(P.dot(U))\n",
    "    U = normalize(U, norm='l2', axis=1)\n",
    "\n",
    "    U, s, V = svds(U, k=args.k)\n",
    "\n",
    "    # FNEM rounding\n",
    "    C = np.zeros((U.shape[0], args.k))\n",
    "    for i in range(U.shape[0]):\n",
    "        j = np.argmax(U[i, :])\n",
    "        C[i, j] = 1\n",
    "    C = normalize(C, norm='l2', axis=0)\n",
    "\n",
    "    for _ in range(100):  # You can adjust the number of iterations\n",
    "        # Update T\n",
    "        U_T_C = U.T @ C\n",
    "        Phi, _, Psi = svd(U_T_C)\n",
    "        T = Phi @ Psi.T\n",
    "\n",
    "        # Update C\n",
    "        C = np.zeros((U.shape[0], args.k))\n",
    "        UT = U @ T\n",
    "        for i in range(U.shape[0]):\n",
    "            j = np.argmax(UT[i, :])\n",
    "            C[i, j] = 1\n",
    "        C = normalize(C, norm='l2', axis=0)\n",
    "\n",
    "    labels = np.argmax(C, axis=1)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def SNEM(W, args):\n",
    "    c = np.array(np.sqrt(W.sum(axis=0))).flatten()\n",
    "    c[c==0] = 1\n",
    "    c = 1.0/c\n",
    "    c = diags(c)\n",
    "\n",
    "    P = normalize(W, norm='l1', axis=1)\n",
    "    R = c.dot(W.T)\n",
    "    r = np.array(np.sqrt(W.sum(axis=1))).flatten()\n",
    "    r[r==0] = 1\n",
    "    r = 1.0/r\n",
    "    r = diags(r)\n",
    "    R = R.dot(r)\n",
    "\n",
    "    m, n = W.shape\n",
    "    dim = min(int(args.dim * args.k), min(m, n) - 1)\n",
    "\n",
    "    # print(f\"dimension={dim}\")\n",
    "\n",
    "    U, s, V = svds(R, k=dim)\n",
    "    s = s**2\n",
    "\n",
    "    alpha = args.alpha\n",
    "    s = (1.0-alpha)/(1.0-alpha*(s))\n",
    "    s = np.array(s).flatten()\n",
    "    s = diags(s).todense()\n",
    "    U = np.asarray(U.dot(s))\n",
    "    U = np.asarray(P.dot(U))\n",
    "    U = normalize(np.asarray(U), norm='l2', axis=1)\n",
    "\n",
    "    U, s, V = svds(U, k=args.k)\n",
    "\n",
    "    # SNEM rounding\n",
    "    C = np.zeros((U.shape[0], args.k))\n",
    "    for i in range(U.shape[0]):\n",
    "        j = np.argmax(U[i, :])\n",
    "        C[i, j] = 1\n",
    "    C = normalize(np.asarray(C), norm='l2', axis=0)\n",
    "\n",
    "    for _ in range(100):  # You can adjust the number of iterations\n",
    "        # Update T\n",
    "        T = U.T @ C\n",
    "\n",
    "        # Update C\n",
    "        C = np.zeros((U.shape[0], args.k))\n",
    "        UT = U @ T\n",
    "        for i in range(U.shape[0]):\n",
    "            j = np.argmax(UT[i, :])\n",
    "            C[i, j] = 1\n",
    "        C = normalize(np.asarray(C), norm='l2', axis=0)\n",
    "\n",
    "    labels = np.argmax(C, axis=1)\n",
    "    return labels\n",
    "\n",
    "def run_clustering(G, algorithm, k, dim=5, alpha=0.2):\n",
    "    adj_matrix = nx.adjacency_matrix(G)\n",
    "    # Convert to scipy sparse matrix if it's not already\n",
    "    W = csr_matrix(adj_matrix)\n",
    "    \n",
    "    # Get dimensions\n",
    "    m, n = W.shape\n",
    "    # print(f\"Matrix shape: {m} x {n}\")\n",
    "    \n",
    "    # Adjust k if necessary\n",
    "    k = min(k, min(m, n) - 1)\n",
    "    \n",
    "    # Create args object to mimic the original code's structure\n",
    "    class Args:\n",
    "        pass\n",
    "    args = Args()\n",
    "    args.k = k\n",
    "    args.dim = dim\n",
    "    args.alpha = alpha\n",
    "    \n",
    "    if algorithm == 'BGC':\n",
    "        return BGC(W, args)\n",
    "    elif algorithm == 'FNEM':\n",
    "        return FNEM(W, args)\n",
    "    elif algorithm == 'SNEM':\n",
    "        return SNEM(W, args)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown algorithm. Choose 'BGC', 'FNEM', or 'SNEM'.\")\n",
    "\n",
    "def array_to_dict_clustering(G, array_clustering):\n",
    "    return {node: int(cluster) for node, cluster in zip(G.nodes(), array_clustering)}\n",
    "\n",
    "def bgc_clustering(G, k):\n",
    "    array_result = run_clustering(G, algorithm='BGC', k=k, dim=5, alpha=0.3)\n",
    "    return array_to_dict_clustering(G, array_result)\n",
    "\n",
    "def fnem_clustering(G, k):\n",
    "    array_result = run_clustering(G, algorithm='FNEM', k=k, dim=5, alpha=0.3)\n",
    "    return array_to_dict_clustering(G, array_result)\n",
    "\n",
    "def snem_clustering(G, k):\n",
    "    array_result = run_clustering(G, algorithm='SNEM', k=k, dim=5, alpha=0.3)\n",
    "    return array_to_dict_clustering(G, array_result)\n",
    "##\n",
    "def leading_eigenvector_clustering(G, k):\n",
    "    \"\"\"\n",
    "    Perform leading eigenvector clustering on a graph.\n",
    "    \n",
    "    Parameters:\n",
    "    G (networkx.Graph): The input graph\n",
    "    k (int): Number of clusters (default is 2)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Mapping of nodes to their cluster assignments\n",
    "    \"\"\"\n",
    "    # Step 1: Compute the Laplacian spectrum\n",
    "    laplacian_eigenvalues = nx.laplacian_spectrum(G)\n",
    "    \n",
    "    # Step 2: Sort eigenvalues and get indices of the k smallest (excluding the smallest)\n",
    "    sorted_indices = np.argsort(laplacian_eigenvalues)\n",
    "    k_smallest_indices = sorted_indices[1:k+1]  # Exclude the smallest eigenvalue\n",
    "    \n",
    "    # Step 3: Compute the corresponding eigenvectors\n",
    "    laplacian_matrix = nx.laplacian_matrix(G).todense()\n",
    "    eigenvectors = np.linalg.eig(laplacian_matrix)[1][:, k_smallest_indices]\n",
    "    \n",
    "    # Step 4: Use K-means to cluster the nodes based on their values in the eigenvectors\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(eigenvectors)\n",
    "    \n",
    "    # Step 5: Create a dictionary mapping nodes to their cluster assignments\n",
    "    return dict(zip(G.nodes(), cluster_labels))\n",
    "###\n",
    "def spectral_clustering_graph(G, k):\n",
    "    # Get the adjacency matrix of the graph as a dense numpy array\n",
    "    adj_matrix = nx.adjacency_matrix(G).toarray()\n",
    "\n",
    "    # Convert to float32 to ensure compatibility\n",
    "    adj_matrix = adj_matrix.astype(np.float32)\n",
    "\n",
    "    # Create the SpectralClustering object\n",
    "    spectral_clustering = SpectralClustering(\n",
    "        n_clusters=k,\n",
    "        affinity='precomputed',\n",
    "        n_init=100,\n",
    "        assign_labels='discretize'\n",
    "    )\n",
    "\n",
    "    # Fit the model and get cluster labels\n",
    "    labels = spectral_clustering.fit_predict(adj_matrix)\n",
    "\n",
    "    # Create a dictionary to store the results\n",
    "    clustering_result = {node: int(label) for node, label in zip(G.nodes(), labels)}\n",
    "\n",
    "    return clustering_result\n",
    "\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(true_clustering, pred_clustering):\n",
    "    # Ensure both dictionaries have the same keys\n",
    "    assert set(true_clustering.keys()) == set(pred_clustering.keys()), \"The dictionaries must have the same keys\"\n",
    "    \n",
    "    # Convert dictionaries to lists, maintaining order\n",
    "    nodes = sorted(true_clustering.keys())\n",
    "    true_labels = [true_clustering[node] for node in nodes]\n",
    "    pred_labels = [pred_clustering[node] for node in nodes]\n",
    "    \n",
    "    # Encode labels as integers\n",
    "    le = LabelEncoder()\n",
    "    true_labels_encoded = le.fit_transform(true_labels)\n",
    "    pred_labels_encoded = le.fit_transform(pred_labels)\n",
    "    \n",
    "    # Calculate NMI and ARI (these are invariant to label permutations)\n",
    "    nmi = normalized_mutual_info_score(true_labels_encoded, pred_labels_encoded)\n",
    "    ari = adjusted_rand_score(true_labels_encoded, pred_labels_encoded)\n",
    "    \n",
    "    # Find the best mapping of predicted labels to true labels\n",
    "    cm = confusion_matrix(true_labels_encoded, pred_labels_encoded)\n",
    "    row_ind, col_ind = linear_sum_assignment(-cm)\n",
    "    best_map = dict(zip(col_ind, row_ind))\n",
    "    \n",
    "    # Remap the predicted labels\n",
    "    pred_labels_remapped = np.array([best_map[label] for label in pred_labels_encoded])\n",
    "    \n",
    "    # Calculate accuracy and F1 score with remapped labels\n",
    "    acc = accuracy_score(true_labels_encoded, pred_labels_remapped)\n",
    "    f1 = f1_score(true_labels_encoded, pred_labels_remapped, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Normalized Mutual Information\": nmi,\n",
    "        \"Adjusted Rand Index\": ari\n",
    "    }\n",
    "\n",
    "def run_clustering_experiment(G, true_clustering, k):\n",
    "    algorithms = {\n",
    "        \"Louvain\": louvain,\n",
    "        \"Girvan_Newman\": girvan_newman,\n",
    "        \"Label_Propagation\": label_propagation,\n",
    "        \"K-means\": kmeans_clustering,\n",
    "        \"K-medoids\": kmedoids_clustering,\n",
    "        \"BGC\": bgc_clustering,\n",
    "        \"FNEM\": fnem_clustering,\n",
    "        \"SNEM\": snem_clustering,\n",
    "        \"LE\": leading_eigenvector_clustering,\n",
    "        \"SC\": spectral_clustering_graph\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, algorithm in algorithms.items():\n",
    "        run_results = {'pred_cluster': None, \"eval\": None, \"time\": None}\n",
    "        try:\n",
    "            # Measure execution time\n",
    "            start_time = time.time()\n",
    "            pred_clustering = algorithm(G, k)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            \n",
    "            # Ensure pred_clustering is a dictionary\n",
    "            if not isinstance(pred_clustering, dict):\n",
    "                raise ValueError(f\"{name} algorithm did not return a dictionary\")\n",
    "            \n",
    "            # Store the clustering results and execution time\n",
    "            run_results['pred_cluster'] = remove_events_from_dict(pred_clustering)\n",
    "            run_results['time'] = execution_time\n",
    "            \n",
    "            # Evaluate the clustering\n",
    "            evaluation = evaluate(true_clustering, run_results['pred_cluster'])\n",
    "            run_results['eval'] = evaluation\n",
    "            results[name] = run_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {name}: {str(e)}\")\n",
    "            results[name] = {\n",
    "                \"eval\": {\n",
    "                    \"Accuracy\": np.nan,\n",
    "                    \"F1 Score\": np.nan,\n",
    "                    \"Normalized Mutual Information\": np.nan,\n",
    "                    \"Adjusted Rand Index\": np.nan\n",
    "                },\n",
    "                \"time\": np.nan\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def remove_events_from_dict(input_dict):\n",
    "    events_to_remove = [f'E{i}' for i in range(1, 15)]\n",
    "    return {k: v for k, v in input_dict.items() if k not in events_to_remove}  \n",
    "    \n",
    "def create_comparison_dataframe(true_clustering, clustering_results):\n",
    "    # Create a list of dictionaries for each row\n",
    "    data = []\n",
    "    \n",
    "    # Ensure consistent order of names based on true_clustering\n",
    "    names = list(true_clustering.keys())\n",
    "    \n",
    "    for name in names:\n",
    "        row = {'Name': name, 'True_Clustering': true_clustering[name]}\n",
    "        \n",
    "        # Add results from each clustering algorithm\n",
    "        for algo, results in clustering_results.items():\n",
    "            if 'pred_cluster' in results and results['pred_cluster'] is not None:\n",
    "                row[algo] = results['pred_cluster'].get(name, None)\n",
    "            else:\n",
    "                row[algo] = None\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the correct column order\n",
    "    columns = ['Name', 'True_Clustering'] + list(clustering_results.keys())\n",
    "    df = df[columns]\n",
    "    \n",
    "    return df\n",
    "def create_latex_table(df, file_name):\n",
    "    output_file = \"tables/comparison_table\"+file_name +\".tex\"\n",
    "    # Define the mapping of full names to shortened names\n",
    "    name_mapping = {\n",
    "        'True_Clustering':'True',\n",
    "        'Louvain': 'Louvain',\n",
    "        'Girvan_Newman': 'GN',\n",
    "        'Label_Propagation': 'LP',\n",
    "        'K-means': 'KM',\n",
    "        'K-medoids': 'KM+',\n",
    "        'BGC': 'BGC',\n",
    "        'FNEM': 'FNEM',\n",
    "        'SNEM': 'SNEM',\n",
    "        'LE': 'LE',\n",
    "        'SC': 'SC'\n",
    "    }\n",
    "    \n",
    "    # Rename the columns\n",
    "    df_renamed = df.rename(columns=name_mapping)\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = ['Name', 'True', 'Louvain', 'GN', 'LP', 'KM', 'KM+', 'BGC', 'FNEM', 'SNEM', 'LE', 'SC']\n",
    "    df_reordered = df_renamed[column_order]\n",
    "    \n",
    "    # Generate LaTeX table\n",
    "    latex_table = df_reordered.to_latex(index=False, escape=False)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    # Write the LaTeX table to a file\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    \n",
    "    print(f\"LaTeX table has been written to {output_file}\")\n",
    "def create_evaluation_comparison_dataframe(results_k2, results_k3):\n",
    "    # Initialize lists to store data\n",
    "    algorithms = []\n",
    "    metrics = ['Accuracy', 'F1 Score', 'Normalized Mutual Information', 'Adjusted Rand Index', 'Time (ms)']\n",
    "    short_metrics = ['Acc', 'F1', 'NMI', 'ARI', 'Time (ms)']\n",
    "    metric_mapping = dict(zip(metrics, short_metrics))\n",
    "    \n",
    "    data = {metric: {'k=2': [], 'k=3': []} for metric in metrics}\n",
    "\n",
    "    # Process results for k=2 and k=3\n",
    "    for algo in results_k2.keys():\n",
    "        algorithms.append(algo)\n",
    "        for metric in metrics[:-1]:  # Exclude 'Time (ms)' from this loop\n",
    "            data[metric]['k=2'].append(results_k2[algo]['eval'][metric])\n",
    "            data[metric]['k=3'].append(results_k3[algo]['eval'][metric])\n",
    "        \n",
    "        # Add time data (convert seconds to milliseconds)\n",
    "        data['Time (ms)']['k=2'].append(results_k2[algo].get('time', float('nan')) * 1000)\n",
    "        data['Time (ms)']['k=3'].append(results_k3[algo].get('time', float('nan')) * 1000)\n",
    "\n",
    "    # Create MultiIndex for columns\n",
    "    column_index = pd.MultiIndex.from_product([short_metrics, ['k=2', 'k=3']], names=['Metric', 'k'])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(index=algorithms, columns=column_index)\n",
    "\n",
    "    # Fill DataFrame with data\n",
    "    for metric, short_metric in metric_mapping.items():\n",
    "        df[short_metric, 'k=2'] = data[metric]['k=2']\n",
    "        df[short_metric, 'k=3'] = data[metric]['k=3']\n",
    "\n",
    "    return df.style.format(decimal='.', thousands=',', precision=2)\n",
    "\n",
    "def create_latex_comparison_table(styled_df):\n",
    "    output_file = \"tables/comparison_table_k2_k3.tex\"\n",
    "    \n",
    "    # Convert Styler to LaTeX\n",
    "    latex_table = styled_df.to_latex(\n",
    "        hrules=True,\n",
    "        multicol_align='c',\n",
    "        clines=\"all;data\",\n",
    "        sparse_index=False\n",
    "    )\n",
    "    \n",
    "    # Optionally, you can add some LaTeX table formatting\n",
    "    latex_table = (\n",
    "        \"\\\\begin{table}[htbp]\\n\"\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\caption{Comparison of Clustering Algorithms}\\n\"\n",
    "        \"\\\\label{tab:comparison}\\n\"\n",
    "        \"\\\\small\\n\"\n",
    "        + latex_table +\n",
    "        \"\\\\end{table}\"\n",
    "    )\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    \n",
    "    print(f\"LaTeX table has been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8cf04ab-596e-4c60-9299-0bbae5aa61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_clustering = {\n",
    "     \"Evelyn Jefferson\":0,\n",
    "     \"Laura Mandeville\":0,\n",
    "     \"Theresa Anderson\":0,\n",
    "     \"Brenda Rogers\":0,\n",
    "     \"Charlotte McDowd\":0,\n",
    "     \"Frances Anderson\":0,\n",
    "     \"Eleanor Nye\":0,\n",
    "     \"Pearl Oglethorpe\":0,\n",
    "     \"Ruth DeSand\":0,\n",
    "     \"Verne Sanderson\":1,\n",
    "     \"Myra Liddel\":1,\n",
    "     \"Katherina Rogers\":1,\n",
    "     \"Sylvia Avondale\":1,\n",
    "     \"Nora Fayette\":1,\n",
    "     \"Helen Lloyd\":1,\n",
    "     \"Dorothy Murchison\":1,\n",
    "     \"Olivia Carleton\":1,\n",
    "     \"Flora Price\":1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7734448d-9ce1-4830-a468-8714a76672aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2ecd44b3df4d7d99d9f5c2518a6ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:00<00:00, 147.36it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:00<00:00, 148.07it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:00<00:00, 137.69it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 193.76it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c26a3c830e44a4c8ffcbdf22a80dd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:00<00:00, 147.65it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:00<00:00, 149.69it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:00<00:00, 130.29it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 132.90it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d3391b51b5451f809c65fa2ee984ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:00<00:00, 149.72it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:00<00:00, 144.03it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:00<00:00, 118.51it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 115.60it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a85ea748a46c29efe253326caba29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:00<00:00, 154.46it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:00<00:00, 143.82it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:00<00:00, 129.70it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 125.04it/s]\n"
     ]
    }
   ],
   "source": [
    "G = nx.davis_southern_women_graph()\n",
    "a2 = run_clustering_experiment(G, true_clustering, 2)\n",
    "a3 = run_clustering_experiment(G, true_clustering, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cea79f68-47d4-4cb4-be0f-daf993f89178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>True_Clustering</th>\n",
       "      <th>Louvain</th>\n",
       "      <th>Girvan_Newman</th>\n",
       "      <th>Label_Propagation</th>\n",
       "      <th>K-means</th>\n",
       "      <th>K-medoids</th>\n",
       "      <th>BGC</th>\n",
       "      <th>FNEM</th>\n",
       "      <th>SNEM</th>\n",
       "      <th>LE</th>\n",
       "      <th>SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evelyn Jefferson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Mandeville</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Theresa Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brenda Rogers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlotte McDowd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frances Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eleanor Nye</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pearl Oglethorpe</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ruth DeSand</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Verne Sanderson</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Myra Liddel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Katherina Rogers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sylvia Avondale</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nora Fayette</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Helen Lloyd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dorothy Murchison</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olivia Carleton</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Flora Price</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  True_Clustering  Louvain  Girvan_Newman  \\\n",
       "0    Evelyn Jefferson                0        0              0   \n",
       "1    Laura Mandeville                0        0              0   \n",
       "2    Theresa Anderson                0        0              0   \n",
       "3       Brenda Rogers                0        0              0   \n",
       "4    Charlotte McDowd                0        0              0   \n",
       "5    Frances Anderson                0        0              0   \n",
       "6         Eleanor Nye                0        3              0   \n",
       "7    Pearl Oglethorpe                0        2              0   \n",
       "8         Ruth DeSand                0        3              0   \n",
       "9     Verne Sanderson                1        1              1   \n",
       "10        Myra Liddel                1        1              2   \n",
       "11   Katherina Rogers                1        1              2   \n",
       "12    Sylvia Avondale                1        1              2   \n",
       "13       Nora Fayette                1        1              2   \n",
       "14        Helen Lloyd                1        1              2   \n",
       "15  Dorothy Murchison                1        2              3   \n",
       "16    Olivia Carleton                1        2              2   \n",
       "17        Flora Price                1        2              2   \n",
       "\n",
       "    Label_Propagation  K-means  K-medoids  BGC  FNEM  SNEM  LE  SC  \n",
       "0                   0        1          1    2     1     1   1   1  \n",
       "1                   0        1          1    2     1     1   1   1  \n",
       "2                   0        1          1    2     1     1   1   1  \n",
       "3                   0        1          1    2     1     1   1   1  \n",
       "4                   0        1          1    2     1     1   1   1  \n",
       "5                   0        1          1    2     1     1   1   1  \n",
       "6                   0        1          0    2     1     1   1   1  \n",
       "7                   0        2          0    1     1     1   1   1  \n",
       "8                   0        2          0    2     1     1   1   1  \n",
       "9                   0        2          0    1     1     1   0   0  \n",
       "10                  0        0          0    1     1     1   0   0  \n",
       "11                  0        0          2    1     1     1   0   0  \n",
       "12                  0        0          2    1     1     1   0   0  \n",
       "13                  0        0          2    1     1     1   0   0  \n",
       "14                  0        0          0    1     1     1   0   0  \n",
       "15                  0        2          0    1     1     1   1   2  \n",
       "16                  1        2          0    1     1     1   1   2  \n",
       "17                  1        2          0    1     1     1   1   2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k3 = create_comparison_dataframe(true_clustering, a3)\n",
    "df_k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f61ff02-1504-40a8-9f22-8a1b9ab984c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>True_Clustering</th>\n",
       "      <th>Louvain</th>\n",
       "      <th>Girvan_Newman</th>\n",
       "      <th>Label_Propagation</th>\n",
       "      <th>K-means</th>\n",
       "      <th>K-medoids</th>\n",
       "      <th>BGC</th>\n",
       "      <th>FNEM</th>\n",
       "      <th>SNEM</th>\n",
       "      <th>LE</th>\n",
       "      <th>SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evelyn Jefferson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Mandeville</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Theresa Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brenda Rogers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlotte McDowd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frances Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eleanor Nye</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pearl Oglethorpe</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ruth DeSand</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Verne Sanderson</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Myra Liddel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Katherina Rogers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sylvia Avondale</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nora Fayette</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Helen Lloyd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dorothy Murchison</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olivia Carleton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Flora Price</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  True_Clustering  Louvain  Girvan_Newman  \\\n",
       "0    Evelyn Jefferson                0        1              0   \n",
       "1    Laura Mandeville                0        1              0   \n",
       "2    Theresa Anderson                0        1              0   \n",
       "3       Brenda Rogers                0        1              0   \n",
       "4    Charlotte McDowd                0        1              0   \n",
       "5    Frances Anderson                0        1              0   \n",
       "6         Eleanor Nye                0        2              0   \n",
       "7    Pearl Oglethorpe                0        2              0   \n",
       "8         Ruth DeSand                0        2              0   \n",
       "9     Verne Sanderson                1        2              0   \n",
       "10        Myra Liddel                1        0              1   \n",
       "11   Katherina Rogers                1        0              1   \n",
       "12    Sylvia Avondale                1        0              1   \n",
       "13       Nora Fayette                1        0              1   \n",
       "14        Helen Lloyd                1        0              1   \n",
       "15  Dorothy Murchison                1        2              2   \n",
       "16    Olivia Carleton                1        0              1   \n",
       "17        Flora Price                1        0              1   \n",
       "\n",
       "    Label_Propagation  K-means  K-medoids  BGC  FNEM  SNEM  LE  SC  \n",
       "0                   0        1          0    1     0     0   0   1  \n",
       "1                   0        1          1    1     0     0   0   1  \n",
       "2                   0        1          0    1     0     0   0   1  \n",
       "3                   0        1          1    1     0     0   0   1  \n",
       "4                   0        1          1    1     0     0   0   1  \n",
       "5                   0        1          0    1     0     0   0   1  \n",
       "6                   0        1          0    1     0     0   0   1  \n",
       "7                   0        1          0    1     0     0   0   1  \n",
       "8                   0        1          0    1     0     0   0   1  \n",
       "9                   0        0          0    1     0     0   0   0  \n",
       "10                  0        0          0    1     0     0   0   0  \n",
       "11                  0        0          0    1     0     0   0   0  \n",
       "12                  0        0          1    1     0     0   0   0  \n",
       "13                  0        0          1    1     0     0   0   0  \n",
       "14                  0        0          0    1     0     0   0   0  \n",
       "15                  0        0          0    1     0     0   0   0  \n",
       "16                  1        0          0    1     0     0   0   0  \n",
       "17                  1        0          0    1     0     0   0   0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k2 = create_comparison_dataframe(true_clustering, a)\n",
    "df_k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60af6f37-9318-4404-890e-d1b887375614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f9566\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th id=\"T_f9566_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Acc</th>\n",
       "      <th id=\"T_f9566_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">F1</th>\n",
       "      <th id=\"T_f9566_level0_col4\" class=\"col_heading level0 col4\" colspan=\"2\">NMI</th>\n",
       "      <th id=\"T_f9566_level0_col6\" class=\"col_heading level0 col6\" colspan=\"2\">ARI</th>\n",
       "      <th id=\"T_f9566_level0_col8\" class=\"col_heading level0 col8\" colspan=\"2\">Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >k</th>\n",
       "      <th id=\"T_f9566_level1_col0\" class=\"col_heading level1 col0\" >k=2</th>\n",
       "      <th id=\"T_f9566_level1_col1\" class=\"col_heading level1 col1\" >k=3</th>\n",
       "      <th id=\"T_f9566_level1_col2\" class=\"col_heading level1 col2\" >k=2</th>\n",
       "      <th id=\"T_f9566_level1_col3\" class=\"col_heading level1 col3\" >k=3</th>\n",
       "      <th id=\"T_f9566_level1_col4\" class=\"col_heading level1 col4\" >k=2</th>\n",
       "      <th id=\"T_f9566_level1_col5\" class=\"col_heading level1 col5\" >k=3</th>\n",
       "      <th id=\"T_f9566_level1_col6\" class=\"col_heading level1 col6\" >k=2</th>\n",
       "      <th id=\"T_f9566_level1_col7\" class=\"col_heading level1 col7\" >k=3</th>\n",
       "      <th id=\"T_f9566_level1_col8\" class=\"col_heading level1 col8\" >k=2</th>\n",
       "      <th id=\"T_f9566_level1_col9\" class=\"col_heading level1 col9\" >k=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row0\" class=\"row_heading level0 row0\" >Louvain</th>\n",
       "      <td id=\"T_f9566_row0_col0\" class=\"data row0 col0\" >0.67</td>\n",
       "      <td id=\"T_f9566_row0_col1\" class=\"data row0 col1\" >0.67</td>\n",
       "      <td id=\"T_f9566_row0_col2\" class=\"data row0 col2\" >0.80</td>\n",
       "      <td id=\"T_f9566_row0_col3\" class=\"data row0 col3\" >0.80</td>\n",
       "      <td id=\"T_f9566_row0_col4\" class=\"data row0 col4\" >0.57</td>\n",
       "      <td id=\"T_f9566_row0_col5\" class=\"data row0 col5\" >0.57</td>\n",
       "      <td id=\"T_f9566_row0_col6\" class=\"data row0 col6\" >0.45</td>\n",
       "      <td id=\"T_f9566_row0_col7\" class=\"data row0 col7\" >0.45</td>\n",
       "      <td id=\"T_f9566_row0_col8\" class=\"data row0 col8\" >11.20</td>\n",
       "      <td id=\"T_f9566_row0_col9\" class=\"data row0 col9\" >2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row1\" class=\"row_heading level0 row1\" >Girvan_Newman</th>\n",
       "      <td id=\"T_f9566_row1_col0\" class=\"data row1 col0\" >0.89</td>\n",
       "      <td id=\"T_f9566_row1_col1\" class=\"data row1 col1\" >0.89</td>\n",
       "      <td id=\"T_f9566_row1_col2\" class=\"data row1 col2\" >0.91</td>\n",
       "      <td id=\"T_f9566_row1_col3\" class=\"data row1 col3\" >0.94</td>\n",
       "      <td id=\"T_f9566_row1_col4\" class=\"data row1 col4\" >0.66</td>\n",
       "      <td id=\"T_f9566_row1_col5\" class=\"data row1 col5\" >0.80</td>\n",
       "      <td id=\"T_f9566_row1_col6\" class=\"data row1 col6\" >0.68</td>\n",
       "      <td id=\"T_f9566_row1_col7\" class=\"data row1 col7\" >0.80</td>\n",
       "      <td id=\"T_f9566_row1_col8\" class=\"data row1 col8\" >91.58</td>\n",
       "      <td id=\"T_f9566_row1_col9\" class=\"data row1 col9\" >62.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row2\" class=\"row_heading level0 row2\" >Label_Propagation</th>\n",
       "      <td id=\"T_f9566_row2_col0\" class=\"data row2 col0\" >0.61</td>\n",
       "      <td id=\"T_f9566_row2_col1\" class=\"data row2 col1\" >0.61</td>\n",
       "      <td id=\"T_f9566_row2_col2\" class=\"data row2 col2\" >0.54</td>\n",
       "      <td id=\"T_f9566_row2_col3\" class=\"data row2 col3\" >0.54</td>\n",
       "      <td id=\"T_f9566_row2_col4\" class=\"data row2 col4\" >0.16</td>\n",
       "      <td id=\"T_f9566_row2_col5\" class=\"data row2 col5\" >0.16</td>\n",
       "      <td id=\"T_f9566_row2_col6\" class=\"data row2 col6\" >0.03</td>\n",
       "      <td id=\"T_f9566_row2_col7\" class=\"data row2 col7\" >0.03</td>\n",
       "      <td id=\"T_f9566_row2_col8\" class=\"data row2 col8\" >1.43</td>\n",
       "      <td id=\"T_f9566_row2_col9\" class=\"data row2 col9\" >1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row3\" class=\"row_heading level0 row3\" >K-means</th>\n",
       "      <td id=\"T_f9566_row3_col0\" class=\"data row3 col0\" >1.00</td>\n",
       "      <td id=\"T_f9566_row3_col1\" class=\"data row3 col1\" >0.67</td>\n",
       "      <td id=\"T_f9566_row3_col2\" class=\"data row3 col2\" >1.00</td>\n",
       "      <td id=\"T_f9566_row3_col3\" class=\"data row3 col3\" >0.79</td>\n",
       "      <td id=\"T_f9566_row3_col4\" class=\"data row3 col4\" >1.00</td>\n",
       "      <td id=\"T_f9566_row3_col5\" class=\"data row3 col5\" >0.54</td>\n",
       "      <td id=\"T_f9566_row3_col6\" class=\"data row3 col6\" >1.00</td>\n",
       "      <td id=\"T_f9566_row3_col7\" class=\"data row3 col7\" >0.44</td>\n",
       "      <td id=\"T_f9566_row3_col8\" class=\"data row3 col8\" >3,344.13</td>\n",
       "      <td id=\"T_f9566_row3_col9\" class=\"data row3 col9\" >1,059.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row4\" class=\"row_heading level0 row4\" >K-medoids</th>\n",
       "      <td id=\"T_f9566_row4_col0\" class=\"data row4 col0\" >0.78</td>\n",
       "      <td id=\"T_f9566_row4_col1\" class=\"data row4 col1\" >0.67</td>\n",
       "      <td id=\"T_f9566_row4_col2\" class=\"data row4 col2\" >0.77</td>\n",
       "      <td id=\"T_f9566_row4_col3\" class=\"data row4 col3\" >0.73</td>\n",
       "      <td id=\"T_f9566_row4_col4\" class=\"data row4 col4\" >0.39</td>\n",
       "      <td id=\"T_f9566_row4_col5\" class=\"data row4 col5\" >0.44</td>\n",
       "      <td id=\"T_f9566_row4_col6\" class=\"data row4 col6\" >0.27</td>\n",
       "      <td id=\"T_f9566_row4_col7\" class=\"data row4 col7\" >0.28</td>\n",
       "      <td id=\"T_f9566_row4_col8\" class=\"data row4 col8\" >1,007.48</td>\n",
       "      <td id=\"T_f9566_row4_col9\" class=\"data row4 col9\" >979.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row5\" class=\"row_heading level0 row5\" >BGC</th>\n",
       "      <td id=\"T_f9566_row5_col0\" class=\"data row5 col0\" >0.50</td>\n",
       "      <td id=\"T_f9566_row5_col1\" class=\"data row5 col1\" >0.94</td>\n",
       "      <td id=\"T_f9566_row5_col2\" class=\"data row5 col2\" >0.33</td>\n",
       "      <td id=\"T_f9566_row5_col3\" class=\"data row5 col3\" >0.94</td>\n",
       "      <td id=\"T_f9566_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_f9566_row5_col5\" class=\"data row5 col5\" >0.74</td>\n",
       "      <td id=\"T_f9566_row5_col6\" class=\"data row5 col6\" >0.00</td>\n",
       "      <td id=\"T_f9566_row5_col7\" class=\"data row5 col7\" >0.78</td>\n",
       "      <td id=\"T_f9566_row5_col8\" class=\"data row5 col8\" >6.76</td>\n",
       "      <td id=\"T_f9566_row5_col9\" class=\"data row5 col9\" >7.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row6\" class=\"row_heading level0 row6\" >FNEM</th>\n",
       "      <td id=\"T_f9566_row6_col0\" class=\"data row6 col0\" >0.50</td>\n",
       "      <td id=\"T_f9566_row6_col1\" class=\"data row6 col1\" >0.50</td>\n",
       "      <td id=\"T_f9566_row6_col2\" class=\"data row6 col2\" >0.33</td>\n",
       "      <td id=\"T_f9566_row6_col3\" class=\"data row6 col3\" >0.33</td>\n",
       "      <td id=\"T_f9566_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_f9566_row6_col5\" class=\"data row6 col5\" >0.00</td>\n",
       "      <td id=\"T_f9566_row6_col6\" class=\"data row6 col6\" >0.00</td>\n",
       "      <td id=\"T_f9566_row6_col7\" class=\"data row6 col7\" >0.00</td>\n",
       "      <td id=\"T_f9566_row6_col8\" class=\"data row6 col8\" >52.33</td>\n",
       "      <td id=\"T_f9566_row6_col9\" class=\"data row6 col9\" >50.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row7\" class=\"row_heading level0 row7\" >SNEM</th>\n",
       "      <td id=\"T_f9566_row7_col0\" class=\"data row7 col0\" >0.50</td>\n",
       "      <td id=\"T_f9566_row7_col1\" class=\"data row7 col1\" >0.50</td>\n",
       "      <td id=\"T_f9566_row7_col2\" class=\"data row7 col2\" >0.33</td>\n",
       "      <td id=\"T_f9566_row7_col3\" class=\"data row7 col3\" >0.33</td>\n",
       "      <td id=\"T_f9566_row7_col4\" class=\"data row7 col4\" >0.00</td>\n",
       "      <td id=\"T_f9566_row7_col5\" class=\"data row7 col5\" >0.00</td>\n",
       "      <td id=\"T_f9566_row7_col6\" class=\"data row7 col6\" >0.00</td>\n",
       "      <td id=\"T_f9566_row7_col7\" class=\"data row7 col7\" >0.00</td>\n",
       "      <td id=\"T_f9566_row7_col8\" class=\"data row7 col8\" >39.69</td>\n",
       "      <td id=\"T_f9566_row7_col9\" class=\"data row7 col9\" >42.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row8\" class=\"row_heading level0 row8\" >LE</th>\n",
       "      <td id=\"T_f9566_row8_col0\" class=\"data row8 col0\" >0.50</td>\n",
       "      <td id=\"T_f9566_row8_col1\" class=\"data row8 col1\" >0.83</td>\n",
       "      <td id=\"T_f9566_row8_col2\" class=\"data row8 col2\" >0.33</td>\n",
       "      <td id=\"T_f9566_row8_col3\" class=\"data row8 col3\" >0.83</td>\n",
       "      <td id=\"T_f9566_row8_col4\" class=\"data row8 col4\" >0.00</td>\n",
       "      <td id=\"T_f9566_row8_col5\" class=\"data row8 col5\" >0.48</td>\n",
       "      <td id=\"T_f9566_row8_col6\" class=\"data row8 col6\" >0.00</td>\n",
       "      <td id=\"T_f9566_row8_col7\" class=\"data row8 col7\" >0.41</td>\n",
       "      <td id=\"T_f9566_row8_col8\" class=\"data row8 col8\" >10.41</td>\n",
       "      <td id=\"T_f9566_row8_col9\" class=\"data row8 col9\" >13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9566_level0_row9\" class=\"row_heading level0 row9\" >SC</th>\n",
       "      <td id=\"T_f9566_row9_col0\" class=\"data row9 col0\" >1.00</td>\n",
       "      <td id=\"T_f9566_row9_col1\" class=\"data row9 col1\" >0.83</td>\n",
       "      <td id=\"T_f9566_row9_col2\" class=\"data row9 col2\" >1.00</td>\n",
       "      <td id=\"T_f9566_row9_col3\" class=\"data row9 col3\" >0.90</td>\n",
       "      <td id=\"T_f9566_row9_col4\" class=\"data row9 col4\" >1.00</td>\n",
       "      <td id=\"T_f9566_row9_col5\" class=\"data row9 col5\" >0.81</td>\n",
       "      <td id=\"T_f9566_row9_col6\" class=\"data row9 col6\" >1.00</td>\n",
       "      <td id=\"T_f9566_row9_col7\" class=\"data row9 col7\" >0.76</td>\n",
       "      <td id=\"T_f9566_row9_col8\" class=\"data row9 col8\" >4.46</td>\n",
       "      <td id=\"T_f9566_row9_col9\" class=\"data row9 col9\" >3.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe9261a9460>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage example\n",
    "df_comparison = create_evaluation_comparison_dataframe(a2, a3)\n",
    "df_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe156e90-9b48-43e4-aeba-140203992890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e09fff73-361d-44f0-b7db-62d19a1b9050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table has been written to tables/comparison_table_k2_k3.tex\n"
     ]
    }
   ],
   "source": [
    "create_latex_comparison_table(df_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4013d94-4ea7-42a0-8e0d-6048fcbd5ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "gt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
